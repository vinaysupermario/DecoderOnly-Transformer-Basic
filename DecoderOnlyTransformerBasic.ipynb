{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b852c2-b47b-4a41-beea-69fa82025d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Import Hand-Made Custom-Transformer\n",
    "from transformer import Config, DecoderOnlyTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af1a9934-5445-496d-a03b-20592c4bd288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /home/shivamkhaneja1/lib/python3.9/site-packages (1.5.1)\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Embedding-1              [8, 128, 640]      32,164,480\n",
      "         Embedding-2              [8, 128, 640]       1,310,720\n",
      "           Dropout-3              [8, 128, 640]               0\n",
      "         LayerNorm-4              [8, 128, 640]           1,280\n",
      "            Linear-5             [8, 128, 1920]       1,230,720\n",
      "           Dropout-6           [8, 8, 128, 128]               0\n",
      "            Linear-7              [8, 128, 640]         410,240\n",
      "           Dropout-8              [8, 128, 640]               0\n",
      "MultiHeadAttention-9              [8, 128, 640]               0\n",
      "        LayerNorm-10              [8, 128, 640]           1,280\n",
      "           Linear-11             [8, 128, 2560]       1,640,960\n",
      "           Linear-12              [8, 128, 640]       1,639,040\n",
      "          Dropout-13              [8, 128, 640]               0\n",
      "      FeedForward-14              [8, 128, 640]               0\n",
      " TransformerBlock-15              [8, 128, 640]               0\n",
      "        LayerNorm-16              [8, 128, 640]           1,280\n",
      "           Linear-17             [8, 128, 1920]       1,230,720\n",
      "          Dropout-18           [8, 8, 128, 128]               0\n",
      "           Linear-19              [8, 128, 640]         410,240\n",
      "          Dropout-20              [8, 128, 640]               0\n",
      "MultiHeadAttention-21              [8, 128, 640]               0\n",
      "        LayerNorm-22              [8, 128, 640]           1,280\n",
      "           Linear-23             [8, 128, 2560]       1,640,960\n",
      "           Linear-24              [8, 128, 640]       1,639,040\n",
      "          Dropout-25              [8, 128, 640]               0\n",
      "      FeedForward-26              [8, 128, 640]               0\n",
      " TransformerBlock-27              [8, 128, 640]               0\n",
      "        LayerNorm-28              [8, 128, 640]           1,280\n",
      "           Linear-29             [8, 128, 1920]       1,230,720\n",
      "          Dropout-30           [8, 8, 128, 128]               0\n",
      "           Linear-31              [8, 128, 640]         410,240\n",
      "          Dropout-32              [8, 128, 640]               0\n",
      "MultiHeadAttention-33              [8, 128, 640]               0\n",
      "        LayerNorm-34              [8, 128, 640]           1,280\n",
      "           Linear-35             [8, 128, 2560]       1,640,960\n",
      "           Linear-36              [8, 128, 640]       1,639,040\n",
      "          Dropout-37              [8, 128, 640]               0\n",
      "      FeedForward-38              [8, 128, 640]               0\n",
      " TransformerBlock-39              [8, 128, 640]               0\n",
      "        LayerNorm-40              [8, 128, 640]           1,280\n",
      "           Linear-41             [8, 128, 1920]       1,230,720\n",
      "          Dropout-42           [8, 8, 128, 128]               0\n",
      "           Linear-43              [8, 128, 640]         410,240\n",
      "          Dropout-44              [8, 128, 640]               0\n",
      "MultiHeadAttention-45              [8, 128, 640]               0\n",
      "        LayerNorm-46              [8, 128, 640]           1,280\n",
      "           Linear-47             [8, 128, 2560]       1,640,960\n",
      "           Linear-48              [8, 128, 640]       1,639,040\n",
      "          Dropout-49              [8, 128, 640]               0\n",
      "      FeedForward-50              [8, 128, 640]               0\n",
      " TransformerBlock-51              [8, 128, 640]               0\n",
      "        LayerNorm-52              [8, 128, 640]           1,280\n",
      "           Linear-53             [8, 128, 1920]       1,230,720\n",
      "          Dropout-54           [8, 8, 128, 128]               0\n",
      "           Linear-55              [8, 128, 640]         410,240\n",
      "          Dropout-56              [8, 128, 640]               0\n",
      "MultiHeadAttention-57              [8, 128, 640]               0\n",
      "        LayerNorm-58              [8, 128, 640]           1,280\n",
      "           Linear-59             [8, 128, 2560]       1,640,960\n",
      "           Linear-60              [8, 128, 640]       1,639,040\n",
      "          Dropout-61              [8, 128, 640]               0\n",
      "      FeedForward-62              [8, 128, 640]               0\n",
      " TransformerBlock-63              [8, 128, 640]               0\n",
      "        LayerNorm-64              [8, 128, 640]           1,280\n",
      "           Linear-65             [8, 128, 1920]       1,230,720\n",
      "          Dropout-66           [8, 8, 128, 128]               0\n",
      "           Linear-67              [8, 128, 640]         410,240\n",
      "          Dropout-68              [8, 128, 640]               0\n",
      "MultiHeadAttention-69              [8, 128, 640]               0\n",
      "        LayerNorm-70              [8, 128, 640]           1,280\n",
      "           Linear-71             [8, 128, 2560]       1,640,960\n",
      "           Linear-72              [8, 128, 640]       1,639,040\n",
      "          Dropout-73              [8, 128, 640]               0\n",
      "      FeedForward-74              [8, 128, 640]               0\n",
      " TransformerBlock-75              [8, 128, 640]               0\n",
      "        LayerNorm-76              [8, 128, 640]           1,280\n",
      "           Linear-77             [8, 128, 1920]       1,230,720\n",
      "          Dropout-78           [8, 8, 128, 128]               0\n",
      "           Linear-79              [8, 128, 640]         410,240\n",
      "          Dropout-80              [8, 128, 640]               0\n",
      "MultiHeadAttention-81              [8, 128, 640]               0\n",
      "        LayerNorm-82              [8, 128, 640]           1,280\n",
      "           Linear-83             [8, 128, 2560]       1,640,960\n",
      "           Linear-84              [8, 128, 640]       1,639,040\n",
      "          Dropout-85              [8, 128, 640]               0\n",
      "      FeedForward-86              [8, 128, 640]               0\n",
      " TransformerBlock-87              [8, 128, 640]               0\n",
      "        LayerNorm-88              [8, 128, 640]           1,280\n",
      "           Linear-89             [8, 128, 1920]       1,230,720\n",
      "          Dropout-90           [8, 8, 128, 128]               0\n",
      "           Linear-91              [8, 128, 640]         410,240\n",
      "          Dropout-92              [8, 128, 640]               0\n",
      "MultiHeadAttention-93              [8, 128, 640]               0\n",
      "        LayerNorm-94              [8, 128, 640]           1,280\n",
      "           Linear-95             [8, 128, 2560]       1,640,960\n",
      "           Linear-96              [8, 128, 640]       1,639,040\n",
      "          Dropout-97              [8, 128, 640]               0\n",
      "      FeedForward-98              [8, 128, 640]               0\n",
      " TransformerBlock-99              [8, 128, 640]               0\n",
      "       LayerNorm-100              [8, 128, 640]           1,280\n",
      "          Linear-101             [8, 128, 1920]       1,230,720\n",
      "         Dropout-102           [8, 8, 128, 128]               0\n",
      "          Linear-103              [8, 128, 640]         410,240\n",
      "         Dropout-104              [8, 128, 640]               0\n",
      "MultiHeadAttention-105              [8, 128, 640]               0\n",
      "       LayerNorm-106              [8, 128, 640]           1,280\n",
      "          Linear-107             [8, 128, 2560]       1,640,960\n",
      "          Linear-108              [8, 128, 640]       1,639,040\n",
      "         Dropout-109              [8, 128, 640]               0\n",
      "     FeedForward-110              [8, 128, 640]               0\n",
      "TransformerBlock-111              [8, 128, 640]               0\n",
      "       LayerNorm-112              [8, 128, 640]           1,280\n",
      "          Linear-113             [8, 128, 1920]       1,230,720\n",
      "         Dropout-114           [8, 8, 128, 128]               0\n",
      "          Linear-115              [8, 128, 640]         410,240\n",
      "         Dropout-116              [8, 128, 640]               0\n",
      "MultiHeadAttention-117              [8, 128, 640]               0\n",
      "       LayerNorm-118              [8, 128, 640]           1,280\n",
      "          Linear-119             [8, 128, 2560]       1,640,960\n",
      "          Linear-120              [8, 128, 640]       1,639,040\n",
      "         Dropout-121              [8, 128, 640]               0\n",
      "     FeedForward-122              [8, 128, 640]               0\n",
      "TransformerBlock-123              [8, 128, 640]               0\n",
      "       LayerNorm-124              [8, 128, 640]           1,280\n",
      "          Linear-125             [8, 128, 1920]       1,230,720\n",
      "         Dropout-126           [8, 8, 128, 128]               0\n",
      "          Linear-127              [8, 128, 640]         410,240\n",
      "         Dropout-128              [8, 128, 640]               0\n",
      "MultiHeadAttention-129              [8, 128, 640]               0\n",
      "       LayerNorm-130              [8, 128, 640]           1,280\n",
      "          Linear-131             [8, 128, 2560]       1,640,960\n",
      "          Linear-132              [8, 128, 640]       1,639,040\n",
      "         Dropout-133              [8, 128, 640]               0\n",
      "     FeedForward-134              [8, 128, 640]               0\n",
      "TransformerBlock-135              [8, 128, 640]               0\n",
      "       LayerNorm-136              [8, 128, 640]           1,280\n",
      "          Linear-137             [8, 128, 1920]       1,230,720\n",
      "         Dropout-138           [8, 8, 128, 128]               0\n",
      "          Linear-139              [8, 128, 640]         410,240\n",
      "         Dropout-140              [8, 128, 640]               0\n",
      "MultiHeadAttention-141              [8, 128, 640]               0\n",
      "       LayerNorm-142              [8, 128, 640]           1,280\n",
      "          Linear-143             [8, 128, 2560]       1,640,960\n",
      "          Linear-144              [8, 128, 640]       1,639,040\n",
      "         Dropout-145              [8, 128, 640]               0\n",
      "     FeedForward-146              [8, 128, 640]               0\n",
      "TransformerBlock-147              [8, 128, 640]               0\n",
      "       LayerNorm-148              [8, 128, 640]           1,280\n",
      "          Linear-149            [8, 128, 50257]      32,164,480\n",
      "================================================================\n",
      "Total params: 124,723,200\n",
      "Trainable params: 124,723,200\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1468.63\n",
      "Params size (MB): 475.78\n",
      "Estimated Total Size (MB): 1944.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "config = Config()\n",
    "model = DecoderOnlyTransformer(config)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, input_size=(128,), batch_size=8, device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554f2519-7621-4d9c-ba3d-585bfaef2a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_path, tokenizer, seq_len, vocab_size):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        with open(file_path, \"r\") as f:\n",
    "            self.text = f.read()\n",
    "\n",
    "        # Tokenize the text and ensure valid token IDs\n",
    "        self.tokenized_text = [\n",
    "            tid if tid < self.vocab_size else self.tokenizer.unk_token_id\n",
    "            for tid in self.tokenizer.encode(self.text)\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_text) // self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get a chunk of the text\n",
    "        start = idx * self.seq_len\n",
    "        end = (idx + 1) * self.seq_len\n",
    "        input_ids = self.tokenized_text[start:end]\n",
    "        target_ids = self.tokenized_text[start + 1:end + 1]\n",
    "\n",
    "        # Pad sequences to fixed length\n",
    "        pad_token = self.tokenizer.pad_token_id\n",
    "        input_ids = input_ids + [pad_token] * (self.seq_len - len(input_ids))\n",
    "        target_ids = target_ids + [pad_token] * (self.seq_len - len(target_ids))\n",
    "\n",
    "        # Convert to tensors and clamp to valid range\n",
    "        input_ids = torch.tensor(input_ids).clamp(max=self.vocab_size-1)\n",
    "        target_ids = torch.tensor(target_ids).clamp(max=self.vocab_size-1)\n",
    "\n",
    "        return input_ids, target_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "348defeb-c746-40a1-9640-25d318b31b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (input_ids, target_ids) in enumerate(dataloader):\n",
    "        input_ids, target_ids = input_ids.to(device), target_ids.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids)  # Shape: [B, T, vocab_size]\n",
    "\n",
    "        # Slice logits and targets to align predictions\n",
    "        logits = logits[:, :-1, :]  # Remove last token (no target)\n",
    "        target_ids = target_ids[:, :-1]  # Align with logits (targets are already shifted)\n",
    "\n",
    "        # Compute loss using .reshape() for non-contiguous tensors\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.size(-1)),  # Reshape to [B*(T-1), vocab_size]\n",
    "            target_ids.reshape(-1)                # Reshape to [B*(T-1)]\n",
    "        )\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Add this line\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Batch {batch_idx + 1}/{len(dataloader)}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch finished: Average Loss = {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7600a473-1523-4f64-956f-6f7c0e2ea60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (338025 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "config = Config()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Ensure padding token is defined\n",
    "\n",
    "# Dataset and DataLoader\n",
    "file_path = \"input.txt\"  # Replace with your input text file path\n",
    "seq_len = 128\n",
    "dataset = TextDataset(file_path, tokenizer, seq_len, config.vocab_size)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Model and optimizer\n",
    "model = DecoderOnlyTransformer(config).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95bd386c-9014-4cc9-8493-6afde8a95e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "EPOCH: 0\n",
      "Batch 100/330: Loss = 6.1635\n",
      "Batch 200/330: Loss = 6.0040\n",
      "Batch 300/330: Loss = 5.4045\n",
      "Epoch finished: Average Loss = 6.0485\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "print(\"Training started...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"EPOCH:\", epoch)\n",
    "    train(model, dataloader, optimizer, criterion, device)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1815de5d-25eb-4c78-b78d-f69cb6fd5f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "EPOCH: 0\n",
      "Batch 100/330: Loss = 5.6672\n",
      "Batch 200/330: Loss = 5.2406\n",
      "Batch 300/330: Loss = 4.7562\n",
      "Epoch finished: Average Loss = 5.1180\n",
      "EPOCH: 1\n",
      "Batch 100/330: Loss = 4.5388\n",
      "Batch 200/330: Loss = 4.7845\n",
      "Batch 300/330: Loss = 4.3562\n",
      "Epoch finished: Average Loss = 4.7542\n",
      "EPOCH: 2\n",
      "Batch 100/330: Loss = 4.4194\n",
      "Batch 200/330: Loss = 4.6380\n",
      "Batch 300/330: Loss = 3.2539\n",
      "Epoch finished: Average Loss = 4.1899\n",
      "EPOCH: 3\n",
      "Batch 100/330: Loss = 1.7323\n",
      "Batch 200/330: Loss = 1.5065\n",
      "Batch 300/330: Loss = 1.4184\n",
      "Epoch finished: Average Loss = 1.7545\n",
      "EPOCH: 4\n",
      "Batch 100/330: Loss = 1.0313\n",
      "Batch 200/330: Loss = 1.0939\n",
      "Batch 300/330: Loss = 0.9371\n",
      "Epoch finished: Average Loss = 1.0321\n",
      "EPOCH: 5\n",
      "Batch 100/330: Loss = 0.6886\n",
      "Batch 200/330: Loss = 0.7724\n",
      "Batch 300/330: Loss = 0.7125\n",
      "Epoch finished: Average Loss = 0.7499\n",
      "EPOCH: 6\n",
      "Batch 100/330: Loss = 0.5846\n",
      "Batch 200/330: Loss = 0.4257\n",
      "Batch 300/330: Loss = 0.3266\n",
      "Epoch finished: Average Loss = 0.4490\n",
      "EPOCH: 7\n",
      "Batch 100/330: Loss = 0.1869\n",
      "Batch 200/330: Loss = 0.2175\n",
      "Batch 300/330: Loss = 0.1833\n",
      "Epoch finished: Average Loss = 0.1855\n",
      "EPOCH: 8\n",
      "Batch 100/330: Loss = 0.1062\n",
      "Batch 200/330: Loss = 0.0911\n",
      "Batch 300/330: Loss = 0.1255\n",
      "Epoch finished: Average Loss = 0.1105\n",
      "EPOCH: 9\n",
      "Batch 100/330: Loss = 0.0644\n",
      "Batch 200/330: Loss = 0.0753\n",
      "Batch 300/330: Loss = 0.0563\n",
      "Epoch finished: Average Loss = 0.0784\n",
      "EPOCH: 10\n",
      "Batch 100/330: Loss = 0.0527\n",
      "Batch 200/330: Loss = 0.0467\n",
      "Batch 300/330: Loss = 0.0928\n",
      "Epoch finished: Average Loss = 0.0654\n",
      "EPOCH: 11\n",
      "Batch 100/330: Loss = 0.1064\n",
      "Batch 200/330: Loss = 0.0798\n",
      "Batch 300/330: Loss = 0.0525\n",
      "Epoch finished: Average Loss = 0.0624\n",
      "EPOCH: 12\n",
      "Batch 100/330: Loss = 0.0724\n",
      "Batch 200/330: Loss = 0.0924\n",
      "Batch 300/330: Loss = 0.0541\n",
      "Epoch finished: Average Loss = 0.0641\n",
      "EPOCH: 13\n",
      "Batch 100/330: Loss = 0.0532\n",
      "Batch 200/330: Loss = 0.0604\n",
      "Batch 300/330: Loss = 0.0823\n",
      "Epoch finished: Average Loss = 0.0682\n",
      "EPOCH: 14\n",
      "Batch 100/330: Loss = 0.0609\n",
      "Batch 200/330: Loss = 0.0686\n",
      "Batch 300/330: Loss = 0.0499\n",
      "Epoch finished: Average Loss = 0.0725\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "\n",
    "print(\"Training started...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"EPOCH:\", epoch)\n",
    "    train(model, dataloader, optimizer, criterion, device)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb8d9ff6-c833-4d2f-bdcc-d8670a858df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer/tokenizer_config.json',\n",
       " 'tokenizer/special_tokens_map.json',\n",
       " 'tokenizer/vocab.json',\n",
       " 'tokenizer/merges.txt',\n",
       " 'tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b4db526-1448-4488-909b-f113302f6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': config  # Your Config object\n",
    "}, \"decoder_transformer.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
